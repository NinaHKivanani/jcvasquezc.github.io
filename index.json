[{"authors":["admin"],"categories":null,"content":"I have performed research and development (R\u0026amp;D) activities related to signal processing and machine learning for health-care and biometric applications since five years now, both in academic and industrial partners. I am coauthor of more than 50 papers related to signal processing and Machine learning in high impact international conferences and jounals. Currently working as a researcher at the Pattern recognition Lab from the Friedrich Alexander Universtity. Passionate about Machine learning, deep learning, speech processing, and natural language processing technologies.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jcvasquezc.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I have performed research and development (R\u0026amp;D) activities related to signal processing and machine learning for health-care and biometric applications since five years now, both in academic and industrial partners. I am coauthor of more than 50 papers related to signal processing and Machine learning in high impact international conferences and jounals. Currently working as a researcher at the Pattern recognition Lab from the Friedrich Alexander Universtity. Passionate about Machine learning, deep learning, speech processing, and natural language processing technologies.","tags":null,"title":"Juan Camilo Vasquez-Correa","type":"authors"},{"authors":["Juan Camilo Vasquez-Correa","others"],"categories":[],"content":"Apkinson is an Android aplication to evaluate continuously the speech and movement symptoms of Parkinson\u0026rsquo;s patients, providing a feedback mechanism about the current stage of the disease. The patients are asked to do different speech and movement exercises everyday, which are selected from an exercise bank that contains a total of 35 exercises. The speech exercises include the phonation of sustained vowels, diadochokinetic utterances, several sentences that the patient has to read, and the description of images that appear in the screen. On the other hand, movement exercises are captured using the inertial sensors of the smartphone to evaluate symptoms in the upper and lower limbs, such as postural tremor, kinetic tremor, finger tapping, gait deficits, among others.\nAt the end of the exercise session, Apkinson evaluates the performance of the patient, while it keeps a register of the results from previous sessions. This analysis will allow the assessment of the progress of the disease of the patients.\n ","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"ddb95fd3f66eb216d740ac98cdd74ca8","permalink":"https://jcvasquezc.github.io/software/apkinson/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/software/apkinson/","section":"software","summary":"a Mobile Solution for Multimodal Assessment of Patients with Parkinson's Disease","tags":["speech processing","Software","Mobile apps","Movement analysis","health-care","Android"],"title":"Apkinson","type":"software"},{"authors":["Felipe Orlando Lopez-Pabon"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"34e833185fede71b41db57993402a25d","permalink":"https://jcvasquezc.github.io/teaching/felipe-lopez/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/felipe-lopez/","section":"teaching","summary":"Ingeniería electrónica, Universidad de Antioquia, 2019","tags":["natural language processing","Biometrics"],"title":"Aplicación del procesamiento de lenguaje natural para verificación de identidad","type":"teaching"},{"authors":["Cristian David Rios-Urrego"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"2fd5cc38498eff3b91899067c79080dd","permalink":"https://jcvasquezc.github.io/teaching/cristian-rios/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/cristian-rios/","section":"teaching","summary":"Ingeniería electrónica, Universidad de Antioquia, 2019","tags":["speech processing","Deep learning","health-care","convolutional neural network"],"title":"Aprendizaje por transferencia en redes neuronales convolucionales para el diagnóstico y monitoreo de la enfermedad de Parkinson usando señales de voz en tres idiomas diferentes","type":"teaching"},{"authors":["GITA research group, University of Antioquia","COLCIENCIAS","Colombian Ministry of Communication Technologies"],"categories":[],"content":"Study to measure the level of Communication and information technologies (TICs) in the public Health Services institutions of Colombia.\n ","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"7ef314e2d409a63ecf77b280678cfa5e","permalink":"https://jcvasquezc.github.io/project/conexion-salud/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/project/conexion-salud/","section":"project","summary":"Study to measure the level of Communication and information technologies (TICs) in  the public Health Services institutions of Colombia","tags":["health-care","Software"],"title":"Conexion Salud","type":"project"},{"authors":["Juan Camilo Vasquez-Correa"],"categories":[],"content":"DisVoice is a python framework designed to compute features from pathological speech. Disvoice computes phonation articulation, and prosody-based features both from sustained vowels and continuous speech utterances with the aim to evaluate the communication capabilities of patients with different voice disorders including diseases with functional origin such as larinx cancer or nodules; craneo-facial based disorders such as hipernasality developed by cleft-lip and palate; or neurodegenerative disorders such as Parkinson\u0026rsquo;s disease.\n","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"dfd567bb8a6eebc991268950b354fbd1","permalink":"https://jcvasquezc.github.io/software/disvoice/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/software/disvoice/","section":"software","summary":"Python framework to extract features from speech","tags":["speech processing","Software","Signal processing","Python"],"title":"Disvoice","type":"software"},{"authors":["Paula Andrea Perez-Toro"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"a4b02c8729761637b03211ec6974e18d","permalink":"https://jcvasquezc.github.io/teaching/paula-perez/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/paula-perez/","section":"teaching","summary":"Ingeniería electrónica, Universidad de Antioquia, 2018","tags":["movement analysis","non-linear dynamics","inertial sensors"],"title":"Gait Assessment of Patients with Parkinson’s Disease using Inertial Sensors and Non-Linear Dynamics Features","type":"teaching"},{"authors":["Martin Strauss"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"9085cc2f284d1e52da5e84849c5175d6","permalink":"https://jcvasquezc.github.io/teaching/martin-strauss/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/martin-strauss/","section":"teaching","summary":"Master in medical engineering, Friedrich Alexander Universität (FAU), 2019.","tags":["speech processing","Deep learning","health-care"],"title":"Modelling of Speech Aspects in Parkinson’s Disease by Multitask Deep Learning","type":"teaching"},{"authors":["Juan Camilo Vasquez-Correa","Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"12e2cdbe301a7d6edfe4c3744ff62b92","permalink":"https://jcvasquezc.github.io/software/neurospeech/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/software/neurospeech/","section":"software","summary":"Toolkit to asses speech impairments in patients with neurological disorders ","tags":["speech processing","Software","Signal processing","health-care","Python"],"title":"Neurospeech","type":"software"},{"authors":["Juan Camilo Vasquez-Correa"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"718b902265b853825e982bdeef95f3cf","permalink":"https://jcvasquezc.github.io/software/phonet/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/software/phonet/","section":"software","summary":"a Keras Python Tool Based on Gated Recurrent Neural Networks to Extract Phonological Posteriors from Speech","tags":["speech processing","Software","Deep learning","recurrent neural networks","Keras","Python"],"title":"Phonet","type":"software"},{"authors":["Marlon Estiben Bedoya-Vargas"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"2e9e8d01447c10a4d5da3bace23a24c8","permalink":"https://jcvasquezc.github.io/teaching/marlon-bedoya/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/marlon-bedoya/","section":"teaching","summary":"Ingeniería electrónica, Universidad de Antioquia, 2018","tags":["movement analysis","Wavelets","inertial sensors"],"title":"Representaciones en Tiempo-Frecuencia en señales de marcha para la detección automática de la enfermedad de Parkinson","type":"teaching"},{"authors":["Linguistic department, University of Antioquia","GITA research group, University of Antioquia"],"categories":[],"content":"Automatic detection of voiced onset time (VOT) for assessment of pathological speech\n","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"4486ef43488985514509c0a4b14d1899","permalink":"https://jcvasquezc.github.io/project/vot/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/project/vot/","section":"project","summary":"Automatic detection of voiced onset time (VOT) for assessment of pathological speech","tags":["Speech processing","Machine learning","health-care"],"title":"VOT","type":"project"},{"authors":["Luis Felipe Gomez-Gomez"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"23ea2e694a7e1ddfc12682de20ff426f","permalink":"https://jcvasquezc.github.io/teaching/luis-gomez/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/luis-gomez/","section":"teaching","summary":"Ingeniería en telecomunicaciones, Universidad de Antioquia, 2018","tags":["Biometrics","convolutional neural networks","deep learning"],"title":"Verificación biométrica de identidad usando reconocimiento de rostros y patrones de tecleo","type":"teaching"},{"authors":["Daniel Escobar-Grisales"],"categories":[],"content":"","date":1565446818,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446818,"objectID":"f4e34146fc59f91ba9dadec54199bd57","permalink":"https://jcvasquezc.github.io/teaching/daniel-escobar/","publishdate":"2019-08-10T09:20:18-05:00","relpermalink":"/teaching/daniel-escobar/","section":"teaching","summary":"Ingeniería electrónica, Universidad de Antioquia, 2019","tags":["Biometrics","Machine learning","Keystroke dynamics"],"title":"Verificación de identidad mediante análisis biométrico basado en la dinámica del tecleo","type":"teaching"},{"authors":["GITA research group, University of Antioquia"],"categories":[],"content":"Speech is the most natural method of communication among humans. The speech signals contain many traits that reflect suitable information from the speaker, including the identity, emotions, or the presence of diseases which alter the quality of life of patients. Automatic recognition of speech traits has many applications including the medical field; for instance, the detection, monitoring, and assessment of voice disorders allow the development of computer aided tools to support the diagnosis and evaluation/screening of patients; the recognition of emotions. Traditional machine learning methods to recognize speech traits are limited by their capability to process raw speech signals, i.e., without any preprocessing or any feature extraction. During several years, the deployment of suitable systems required the knowledge of an expert in a specific topic to obtain the most informative features to model the information from data, which consumes time and resources that are not always available. This project aims to develop and test different architectures of DNNs to perform the automatic detection of different traits in speech. Two different approaches will be addressed: (1) the raw speech signal will be considered as the input, and (2) several features will be extracted from the signals and those feature vectors will be the input of the system. We will compare both approaches in order to conclude to which extent it is possible to work only with the raw signal and obtain interpretable results such that can be used in the clinical practice. In this proposal, DNN-based methods will be considered to three different problems: (1) classification/detection of multiple voice disorders, (2) monitoring of patients, and (3) detection of emotions and other paralinguistic aspects from speech.\n","date":1565446350,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565446350,"objectID":"2c5823966e6be782aac910ea7e012795","permalink":"https://jcvasquezc.github.io/project/deep-speech/","publishdate":"2019-08-10T09:12:30-05:00","relpermalink":"/project/deep-speech/","section":"project","summary":"Analysis of architectures based on deep learning methods to evaluate and recognize traits in speech signals","tags":["Paralinguistics","Speech processing","Deep learning"],"title":"Deep Speech","type":"project"},{"authors":["GITA research group, University of Antioquia","COLCIENCIAS"],"categories":[],"content":"Human emotions detection considering speech signals is a field that has attracted the attention of the research community since the last years. Several situations where the human integrity and security is at risk have been addressed; particularly the analysis of speech in emergency calls or in call-centers, are an interesting scenario. This project aimed to develop a methodology to classify different types of emotions such as anger, anxiety, disgust, and desperation, in scenarios where the speech signal is contaminated with noise or is coded by telephone channels.\n","date":1565437580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565437580,"objectID":"be1642dfe55353356e4cb55207eaa0bd","permalink":"https://jcvasquezc.github.io/project/emotions/","publishdate":"2019-08-10T06:46:20-05:00","relpermalink":"/project/emotions/","section":"project","summary":"Human emotions detection considering speech signals is a field that has attracted the attention of the research community since the last years. Several situations where the human integrity and security is at risk have been addressed; particularly the analysis of speech in emergency calls or in call-centers, are an interesting scenario. This project aimed to develop a methodology to classify different types of emotions such as anger, anxiety, disgust, and desperation, in scenarios where the speech signal is contaminated with noise or is coded by telephone channels.","tags":["Paralinguistics","Speech processing","Machine learning"],"title":"Automatic recognition of emotions from speech","type":"project"},{"authors":["CSLP from Jhons Hopkins University","Pattern recognition Lab, Friedrich Alexander University (FAU)","University of Toronto","University of Sheffield","GITA research group, University of Antioquia"],"categories":[],"content":"Alzheimer’s disease (AD) is the most common neurodegenerative disorder. It generally deteriorates memory function, then language, then executive function to the point where simple activities of daily living (ADLs) become difficult. Parkinson’s disease (PD) is the second most common neurodegenerative disease, also primarily affecting individuals of advanced age. Its cardinal symptoms include akinesia, tremor, rigidity, and postural imbalance. Together, AD and PD afflict approximately 55 million people, and there is no cure. Currently, professional or informal caregivers look after these individuals, either at home or in long-term care facilities. Caregiving is already a great, expensive burden on the system, but things will soon become far worse. Populations of many nations are aging rapidly and, with over 12% of people above the age of 65 having either AD or PD, incidence rates are set to triple over the next few decades. Monitoring and assessment are vital, but current models are unsustainable. Patients need to be monitored regularly (e.g. to check if medication needs to be updated), which is expensive, time-consuming, and especially difficult when travelling to the closest neurologist is unrealistic. Monitoring patients using non-intrusive sensors to collect data during ADLs from speech, gait, and handwriting, can help to reduce the burden.\n","date":1565436927,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565436927,"objectID":"82c4e841c240197004f2da7c0cd05356","permalink":"https://jcvasquezc.github.io/project/remote/","publishdate":"2019-08-10T06:35:27-05:00","relpermalink":"/project/remote/","section":"project","summary":"Remote Monitoring of Neurodegeneration through Speech","tags":["Health-care","Speech processing","Natural Language processing","Machine learning"],"title":"2016 Third Frederick Jelinek Memorial Summer Workshop","type":"project"},{"authors":["Pattern recognition Lab, Friedrich Alexander University (FAU)","GITA research group, Unversity of Antioquia"],"categories":["Deep learning","Machine learning","Signal processing","Health-care"],"content":"The main aim of this project is to develop a method to evaluate the motor impairments and the neurological state of patients with Parkinson\u0026rsquo;s Disease using three bio-signals: speech, handwriting and gait. This research work is suitable for the development of computer aided tools to evaluate the motor impairments of patients with different neurodegenerative disorders considering information from different bio\u0026ndash;signals to take accurate decisions about the treatment of the patients.\n","date":1565436573,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565436573,"objectID":"8c60b6875141d1b008d954773c22f1e8","permalink":"https://jcvasquezc.github.io/project/multimodal/","publishdate":"2019-08-10T06:29:33-05:00","relpermalink":"/project/multimodal/","section":"project","summary":"Asynchronous Non-Intrusive Multi-Modal Analysis of Bio-Signals for the Automatic evaluation of the Neurological State of People With Parkinson's Disease","tags":["Deep learning","Machine learning","Signal processing","Health-care"],"title":"Multimodal PD","type":"project"},{"authors":["European Union","Pattern recognition Lab, Friedrich Alexander University (FAU)"],"categories":[],"content":"There are an increasing number of people across Europe with debilitating speech pathologies (e.g., due to stroke, Parkinson\u0026rsquo;s, etc). These groups face communication problems that can lead to social exclusion. They are now being further marginalised by a new wave of speech technology that is increasingly woven into everyday life but which is not robust to atypical speech. TAPAS is a Horizon 2020 Marie Skłodowska-Curie Actions Innovative Training Network European Training Network (MSCA-ITN-ETN) project that aims to transform the well being of these people. The TAPAS work programme targets three key research problems: (a) Detection: We will develop speech processing techniques for early detection of conditions that impact on speech production. The outcomes will be cheap and non-invasive diagnostic tools that provide early warning of the onset of progressive conditions such as Alzheimer\u0026rsquo;s and Parkinson\u0026rsquo;s. (b) Therapy: We will use newly-emerging speech processing techniques to produce automated speech therapy tools. These tools will make therapy more accessible and more individually targeted. Better therapy can increase the chances of recovering intelligible speech after traumatic events such a stroke or oral surgery. \u0026copy; Assisted Living: We will re-design current speech technology so that it works well for people with speech impairments and also helps in making informed clinical choices. People with speech impairments often have other co-occurring conditions making them reliant on carers. Speech-driven tools for assisted-living are a way to allow such people to live more independently. TAPAS adopts an inter-disciplinary and multi-sectorial approach. The consortium includes clinical practitioners, academic researchers and industrial partners, with expertise spanning speech engineering, linguistics and clinical science. All members have expertise in some element of pathological speech. This rich network will train a new generation of 15 researchers, equipping them with the skills and resources necessary for lasting success.\n","date":1565435177,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565435177,"objectID":"5ff1ceda1edb549cf50871e6d1126c72","permalink":"https://jcvasquezc.github.io/project/tapas/","publishdate":"2019-08-10T06:06:17-05:00","relpermalink":"/project/tapas/","section":"project","summary":"Training Network on Automatic Processing of PAthological Speech","tags":["Speech processing","Machine learning","Health care","Health tech"],"title":"TAPAS","type":"project"},{"authors":["Cristian David Rios-Urrego","Juan Camilo Vásquez-Correa","Jesus Francisco Vargas-Bonilla","Elmar Nöth","Francisco Lopera","Juan Rafael Orozco-Arroyave"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"0095a5965b3354e1634f33cdfc7c0afb","permalink":"https://jcvasquezc.github.io/publication/rios-2019-analysis/","publishdate":"2019-08-07T14:57:01.365214Z","relpermalink":"/publication/rios-2019-analysis/","section":"publication","summary":"Background and objectives: Parkinson’s disease is a neurological disorder that affects the motor system producing lack of coordination, resting tremor, and rigidity. Impairments in handwriting are among the main symptoms of the disease. Handwriting analysis can help in supporting the diagnosis and in monitoring the progress of the disease. This paper aims to evaluate the importance of different groups of features to model handwriting deficits that appear due to Parkinson’s disease; and how those features are able to discriminate between Parkinson’s disease patients and healthy subjects. Methods: Features based on kinematic, geometrical and non-linear dynamics analyses were evaluated to classify Parkinson’s disease and healthy subjects. Classifiers based on K-nearest neighbors, support vector machines, and random forest were considered. Results: Accuracies of up to 93.1% were obtained in the classification of patients and healthy control subjects. A relevance analysis of the features indicated that those related to speed, acceleration, and pressure are the most discriminant. The automatic classification of patients in different stages of the disease shows κ indexes between 0.36 and 0.44. Accuracies of up to 83.3% were obtained in a different dataset used only for validation purposes.Conclusions: The results confirmed the negative impact of aging in the classification process when we considered different groups of healthy subjects. In addition, the results reported with the separate validation set comprise a step towards the development of automated tools to support the diagnosis process in clinical practice.","tags":["handwriting analysis","health-care","Machine learning","non-linear dynamics"],"title":"Analysis and evaluation of handwriting in patients with Parkinson’s disease using kinematic, geometrical, and non-linear features","type":"publication"},{"authors":["Nina Hosseini-Kivanani","Juan Camilo Vásquez-Correa","Manfred Stede","Elmar Nöth"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"4fff027a7aabc98f2ae41fbb0cd046bd","permalink":"https://jcvasquezc.github.io/publication/hosseini-2019-automated/","publishdate":"2019-08-07T14:58:03.788903Z","relpermalink":"/publication/hosseini-2019-automated/","section":"publication","summary":"Speech deficits are common symptoms amongParkinson’s Disease (PD) patients. The automatic assessment of speech signals is promising for the evaluation of the neurological state and the speech quality of the patients. Recently, progress has been made in applying machine learning and computational methods to automatically evaluate the speech of PD patients. In the present study, we plan to analyze the speech signals of PD patients and healthy control (HC) subjects in three different languages: German, Spanish, and Czech, with the aim to identify biomarkers to discriminate between PD patients and HC subjects and to evaluate the neurological state of the patients. Therefore, the main contribution of this study is the automatic classification of PD patients and HC subjects in different languages with focusing on phonation, articulation, and prosody. We will focus on an intelligibility analysis based on automatic speech recognition systems trained on these three languages. This is one of the first studies done that considers the evaluation of the speech of PD patients in different languages. The purpose of this research proposal is to build a model that can discriminate PD and HC subjects even when the language used for train and test is different.","tags":["Speech processing","speech recognition","Machine learning","health-care","Kaldi"],"title":"Automated Cross-language Intelligibility Analysis of Parkinson’s Disease Patients Using Speech Recognition Technologies","type":"publication"},{"authors":["T Arias Vergara","S Gollwitzer","J. R.  Orozco-Arroyave","J. C. Vasquez-Correa","E Nöth","C Högerle","M Schuster"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2dd72230ad8ddbe0ef803d1e4a830b4a","permalink":"https://jcvasquezc.github.io/publication/vergara-2019-speech/","publishdate":"2019-08-07T14:58:03.789256Z","relpermalink":"/publication/vergara-2019-speech/","section":"publication","summary":" Introduction: The onset of deafness affects speech in different ways. Speech differences of Cochlear Implant (CI) users with pre- and postlingual deafness are examined using acoustic features extracted automatically from speech. Methods: Utterances of 22 prelingual (15 up to 71 years old) and 22 postlingual CI users (15 up to 78 years old) were analyzed. All patients read 97 words, which contain every phoneme of the German language in different positions within the words. Speech analysis is performed in the transitions from voiceless to voiced sounds that mark the precise control of speech movement patterns. To extract the transitions, we search for the boundary between voiceless and voiced sounds using the fundamental frequency with a constant segment of 80 ms to the left and right. The feature set includes 13 Mel-Frequency Cepstral Coefficients and their 1st and 2nd derivatives. The mean, standard deviation, skewness and kurtosis are computed from the descriptors, forming a 156-dimensional feature vector. Wilcoxon signed-rank test is used to find differences between the pre- and postlingual groups. Results:  The Wilcoxon signed-rank test was performed for each descriptor and significant differences between the pre- and postlingual groups (α $Conclusions:  Speech patterns differ significantly between pre- and postlingual CI users at the transitions of voiceless to voiced sounds. Other acoustic features are to be examined and considered in the rehabilitation after cochlear implantation.","tags":["Speech processing","health-care"],"title":"Speech differences between CI users with pre-and postlingual onset of deafness detected by speech processing methods on voiceless to voice transitions","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Tomás Arias-Vergara","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e7f0c22890e09a8bc3a54bdf0e7583f2","permalink":"https://jcvasquezc.github.io/publication/vasquez-2018-multitask/","publishdate":"2019-08-07T14:57:01.361025Z","relpermalink":"/publication/vasquez-2018-multitask/","section":"publication","summary":"Parkinson's disease is a neurodegenerative disorder characterized by a variety of motor and non-motor symptoms. Particularly, several speech impairments appear in the initial stages of the disease, which affect aspects related to respiration and the movement of muscles and limbs in the vocal tract. Most of the studies in the literature aim to assess only one specific task from the patients, such as the classification of patients vs. healthy speakers, or the assessment of the neurological state of the patients. This study proposes a multitask learning approach based on convolutional neural networks to assess at the same time several speech deficits of the patients. A total of eleven speech aspects are considered, including difficulties of the patients to move articulators such as lips, palate, tongue and larynx. According to the results, the proposed approach improves the generalization of the convolutional network, producing more representative feature maps to assess the different speech symptoms of the patients. The multitask learning scheme improves in of up to 4% the average accuracy relative to single networks trained to assess each individual speech aspect.","tags":["Speech processing","Deep learning","health-care","convolutional neural networks","multitask learning"],"title":"A Multitask Learning Approach to Assess the Dysarthria Severity in Patients with Parkinson's Disease","type":"publication"},{"authors":["Paula Andrea Pérez-Toro","Juan Camilo Vásquez-Correa","Tomas Arias-Vergara","Nicanor Garcia-Ospina","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"0a2c2d70e399e6853d86d0f1241f74df","permalink":"https://jcvasquezc.github.io/publication/perez-2018-non/","publishdate":"2019-08-07T14:57:01.36554Z","relpermalink":"/publication/perez-2018-non/","section":"publication","summary":"Parkinson’s disease is a neuro-degenerative disorder characterized by different motor symptoms, including several gait impairments. Gait analysis is a suitable tool to support the diagnosis and to monitor the state of the disease. This study proposes the use of non-linear dynamics features extracted from gait signals obtained from inertial sensors for the automatic detection of the disease. We classify two groups of healthy controls (Elderly and Young) and Parkinson’s patients with several classifiers. Accuracies ranging from 86% to 92% are obtained, depending on the age of the healthy control subjects.","tags":["Inertial sensors","Machine learning","health-care","Movement analysis","non-linear dynamics"],"title":"A Non-linear Dynamics Approach to Classify Gait Signals of Patients with Parkinson’s Disease","type":"publication"},{"authors":["Luis Felipe Parra-Gallego","Tomás Arias-Vergara","Juan Camilo Vásquez-Correa","Nicanor Garcia-Ospina","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"89873c00479ee7dbb7c858e217fb064b","permalink":"https://jcvasquezc.github.io/publication/parra-2018-automatic/","publishdate":"2019-08-07T14:58:03.789977Z","relpermalink":"/publication/parra-2018-automatic/","section":"publication","summary":"This paper presents preliminary results for the analysis of intelligibility in the speech of Parkinson's Disease (PD) patients. An automatic speech recognition system is used to compute the word error rate (WER), the Levenshtein distance, and the similitude based dynamic time warping. The corpus of the speech recognizer is formed with speech recordings of three Diadochokinetic speech tasks: /pa-ta-ka/, /pa-ka-ta/, and /pe-ta-ka/. The data consist of 50 PD patients and 50 Healthy Controls. According to the results, the recognition error is lower for the healthy speakers (WER = 2.70%) respect to the PD patients (WER = 11.3%).","tags":["Speech processing","Speech recognition","Kaldi","health-care"],"title":"Automatic Intelligibility Assessment of Parkinson's Disease with Diadochokinetic Exercises","type":"publication"},{"authors":["Nicanor Garcia","Juan Camilo-Vásquez Correa","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"fc3923d14f5147646e45d19030aaa0ce","permalink":"https://jcvasquezc.github.io/publication/garcia-2018-multimodal/","publishdate":"2019-08-07T14:58:03.790691Z","relpermalink":"/publication/garcia-2018-multimodal/","section":"publication","summary":"Parkinson's Disease (PD) is a neurodegenerative disorder characterized by a variety of motor symptoms. PD patients show several motor deficits, including speech deficits, impaired handwriting and gait disturbances. In this work we propose a methodology to fuse i-vectors extracted from three different bio-signals: speech, handwriting and gait. These i-vectors are used to classify Parkinson's Disease patients and healthy controls and to evaluate the neurological state of the patients. Speech i-vectors are extracted from MFCCs, handwriting i-vectors are extracted from kinematic features and gait i-vectors are extracted from modified MFCCs computed from inertial sensor signals. Two fusion strategies are tested: concatenating the i-vectors of a subject to form a super-i-vector with information from the three bio-signals and score pooling. The proposed fusion methods leads to better classification results respect to the separate analysis with each bio-signal, reaching an accuracy of up to 85%.","tags":["Speech processing","movement analysis","Machine learning","health-care","i-vectors","Kaldi"],"title":"Multimodal I-vectors to Detect and Evaluate Parkinson's Disease","type":"publication"},{"authors":["Juan Camilo Vasquez-Correa","Tomas Arias-Vergara","Juan Rafael Orozco-Arroyave","Björn Eskofier","Jochen Klucken","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"06040eee4fbacd2de92648b23d1bbcb4","permalink":"https://jcvasquezc.github.io/publication/vasquez-2018-multimodal/","publishdate":"2019-08-07T14:57:01.363238Z","relpermalink":"/publication/vasquez-2018-multimodal/","section":"publication","summary":"Parkinson's disease is a neurodegenerative disorder characterized by a variety of motor symptoms. Particularly, difficulties to start/stop movements have been observed in patients. From a technical/diagnostic point of view, these movement changes can be assessed by modeling the transitions between voiced and unvoiced segments in speech, the movement when the patient starts or stops a new stroke in handwriting, or the movement when the patient starts or stops the walking process. This study proposes a methodology to model such difficulties to start or to stop movements considering information from speech, handwriting, and gait. We used those transitions to train convolutional neural networks to classify patients and healthy subjects. The neurological state of the patients was also evaluated according to different stages of the disease (initial, intermediate, and advanced). In addition, we evaluated the robustness of the proposed approach when considering speech signals in three different languages: Spanish, German, and Czech. According to the results, the fusion of information from the three modalities is highly accurate to classify patients and healthy subjects, and it shows to be suitable to assess the neurological state of the patients in several stages of the disease. We also aimed to interpret the feature maps obtained from the deep learning architectures with respect to the presence or absence of the disease and the neurological state of the patients. As far as we know, this is one of the first works that considers multimodal information to assess Parkinson's disease following a deep learning approach.","tags":["Speech processing","Deep learning","handwriting analysis","movement analysis","Inertial sensors","health-care","convolutional neural networks"],"title":"Multimodal assessment of Parkinson's disease: a deep learning approach","type":"publication"},{"authors":["Juan Rafael Orozco-Arroyave","Juan Camilo Vásquez-Correa","Jesús Francisco Vargas-Bonilla","Raman Arora","Najim Dehak","Phani S Nidadavolu","Heidi Christensen","Frank Rudzicz","Maria Yancheva","H Chinaei"," others"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"7eb7cd7090293251a1c4f565d680ba1d","permalink":"https://jcvasquezc.github.io/publication/orozco-2018-neurospeech/","publishdate":"2019-08-07T14:57:01.3586Z","relpermalink":"/publication/orozco-2018-neurospeech/","section":"publication","summary":"A new software for modeling pathological speech signals is presented in this paper. The software is called NeuroSpeech. This software enables the analysis of pathological speech signals considering different speech dimensions: phonation, articulation, prosody, and intelligibility. All the methods considered in the software have been validated in previous experiments and publications. The current version of NeuroSpeech was developed to model dysarthric speech signals from people with Parkinson's disease; however, the structure of the software allows other computer scientists or developers to include other pathologies and/or other measures in order to complement the existing options. Three different tasks can be performed with the current version of the software: (1) the modeling of the speech recordings considering the aforementioned speech dimensions, (2) the automatic discrimination of Parkinson's vs. non-Parkinson's speech signals (if the user has access to recordings of other pathologies, he/she can re-train the system to perform the detection of other diseases), and (3) the prediction of the neurological state of the patient according to the Unified Parkinson's Disease Rating Scale (UPDRS) score. The prediction of the dysarthria level according to the Frenchay Dysarthria Assessment scale is also provided (the user can also train the system to perform the prediction of other kind of scales or degrees of severity). To the best of our knowledge, this is the first software with the characteristics described above, and we consider that it will help other researchers to contribute to the state-of-the-art in pathological speech assessment from different perspectives, e.g., from the clinical point of view for interpretation, and from the computer science point of view enabling the test of different measures and pattern recognition techniques.","tags":["Speech processing","Software","health-care","Python"],"title":"NeuroSpeech: An open-source software for Parkinson's speech analysis","type":"publication"},{"authors":["Nicanor Garcia-Ospina","Tomas Arias-Vergara","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Milos Cernak","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"bc92aa0da6380662407d391277523bb9","permalink":"https://jcvasquezc.github.io/publication/garcia-2018-phonological/","publishdate":"2019-08-07T14:58:03.790341Z","relpermalink":"/publication/garcia-2018-phonological/","section":"publication","summary":"Speech disorders are common symptoms among Parkinson’s disease patients and affect the speech of patients in different aspects. Currently, there are few studies that consider the phonological dimension of Parkinson’s speech. In this work, we use a recently developed method to extract phonological features from speech signals. These features are based on the Sound Patterns of English phonological model. The extraction is performed using pre-trained Deep Neural Networks to infer the probabilities of phonological features from short-time acoustic features. An i-vector extractor is trained with the phonological features. The extracted i-vectors are used to classify patients and healthy speakers and assess their neurological state and dysarthria level. This approach could be helpful to assess new specific speech aspects such as the movement of different articulators involved in the speech production process.","tags":["Speech processing","Machine learning","health-care","i-vectors","computational linguistics","Kaldi"],"title":"Phonological i-Vectors to Detect Parkinson's Disease","type":"publication"},{"authors":["Marlon Estiben Bedoya-Vargas","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"58741cc5fa018a389db50be8ec8a4f0d","permalink":"https://jcvasquezc.github.io/publication/bedoya-2018-representaciones/","publishdate":"2019-08-07T14:58:03.789627Z","relpermalink":"/publication/bedoya-2018-representaciones/","section":"publication","summary":"La Enfermedad de Parkinson (EP) es un desorden neurodegenerativo del sistema nervioso central, cuyas características principales incluyen entre otras la rigidez, bradicinesia y pérdida de los reflejos posturales. El diagnóstico de la EP está basado en análisis de la historia clínica y evaluaciones físicas realizadas a los pacientes. El monitoreo del estado neurológico de los pacientes está basado en valoraciones subjetivas que realizan los neurólogos. El análisis de la marcha usando sensores inerciales aparece como un instrumento sencillo y útil para ayudar en el proceso de diagnóstico y monitoreo de los pacientes con EP. En este artículo usamos el sistema eGaIT, el cual captura señales de acelerómetro y giróscopo del proceso de marcha para evaluar las habilidades motoras de los pacientes. Las transformadas de Fourier y Wavelet son utilizadas para extraer medidas basadas en energía y entropía en el dominio de Tiempo-Frecuencia. Las características extraídas son utilizadas para discriminar entre pacientes con EP y personas sanas. De acuerdo con los resultados, es posible clasificar estos dos grupos con una precisión de hasta el 94 %.","tags":["Inertial sensors","Machine learning","health-care","Movement analysis"],"title":"Representaciones tiempo-frecuencia basadas en sensores inerciales para caracterizar la marcha en la enfermedad de Parkinson","type":"publication"},{"authors":["Tomas Arias-Vergara","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"8791e7b6353c62300f4708f48b1b3deb","permalink":"https://jcvasquezc.github.io/publication/arias-2018-speaker/","publishdate":"2019-08-07T14:57:01.363557Z","relpermalink":"/publication/arias-2018-speaker/","section":"publication","summary":"Symptoms of Parkinson’s disease vary from patient to patient. Additionally, the progression of those symptoms also differs among patients. Most of the studies on the analysis of speech of people with Parkinson’s disease do not consider such an individual variation. This paper presents a methodology for the automatic and individual monitoring of speech disorders developed by PD patients. The neurological state and dysarthria level of the patients are evaluated. The proposed system is based on individual speaker models which are created for each patient. Two different models are evaluated, the classical GMM–UBM and the i–vectors approach. These two methods are compared with respect to a baseline found with a traditional Support Vector Regressor. Different speech aspects (phonation, articulation, and prosody) are considered to model recordings of spontaneous speech and a read text. A multi-aspect coefficient is proposed with the aim of incorporating information from all of these speech aspects into a single measure. Two different scenarios are considered to assess a set with seven PD patients: (1) the longitudinal test set which consists of speech recordings captured in five recording sessions distributed from 2012 to 2016, and (2) the at-home test set which consists of speech recordings captured in the home of the same seven patients during 4 months (one day per month, four times per day). The UBM is trained with the recordings of 100 speakers (50 with Parkinson’s disease and 50 healthy speakers) captured with controlled acoustic conditions and a professional audio-setting. With the aim of evaluating the suitability of the proposed approaches and the possibility of extending this kind of systems to remotely assess the speech of the patients, a total of five different communication channels (sound-proof booth, Skype®, Hangouts®, mobile phone, and land-line) are considered to train and test the system. Due to the reduced number of recording sessions in the longitudinal test set, the experiments that involved this set are evaluated with the Pearson’s correlation. The experiments with the at-home test set are evaluated with the Spearman’s correlation. The results estimating the dysarthria level of the patients in the at-home test set indicate a correlation of 0.55 with a modified version of the Frenchay Dysarthria Assessment scale when the GMM-UBM model is applied upon the Skype® recordings. The results in the longitudinal test set indicate a correlation of 0.77 using a model based on i-vectors with recordings captured in the sound-proof-booth. The evaluation of the neurological state of the patients in the longitudinal test set shows correlations of up to 0.55 with the Movement Disorder Society - Unified Parkinson’s Disease Rating Scale also using models based on i-vectors created with Skype® recordings. These results suggest that the i–vector approach is suitable when the acoustic conditions among recording sessions differ (longitudinal test set). The GMM-UBM approach seems to be more suitable when the acoustic conditions do not change a lot among recording sessions (at-home test set). Particularly, the best results were obtained with the Skype® calls, which can be explained due to several preprocessing stages that this codec applies to the audio signals. In general, the results suggest that the proposed approaches are suitable for tele-monitoring the dysarthria level and the neurological state of PD patients","tags":["Speech processing","Machine learning","health-care","user-modeling","i-vectors"],"title":"Speaker models for monitoring Parkinson’s disease progression considering different communication channels and acoustic conditions","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Tobias Bocklet","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"88f859ee9aafa4d2837fc0c5b27cecaa","permalink":"https://jcvasquezc.github.io/publication/vasquez-2018-towards/","publishdate":"2019-08-07T14:57:01.362902Z","relpermalink":"/publication/vasquez-2018-towards/","section":"publication","summary":"Background: Parkinson's disease (PD) is a neurological disorder that produces motor and non-motor impairments. The evaluation of motor symptoms is currently performed following the third section of the Movement Disorder Society – Unified Parkinson's Disease Rating Scale (MDS-UPDRS-III); however, only one item of that scale is related to speech impairments. It is necessary to develop a specific scale such that considers those aspects related to speech impairments of the patients.Aims: (i) To introduce and evaluate the suitability of a modified version of the Frenchay Dysarthria Assessment (m-FDA) scale to quantify the dysarthria level of PD patients; (ii) to objectively model dysarthric speech signals considering four speech dimensions; (iii) to develop a methodology, based on speech processing and machine learning methods, to automatically quantify/predict the dysarthria level of patients with PD.Methods: The speech recordings are modeled using features extracted from several dimensions of speech: phonation, articulation, prosody, and intelligibility. The dysarthria level is quantified using linear and non-linear regression models. Speaker models based on i-vectors are also explored.Result and conclusion: The m-FDA scale was introduced to assess the dysarthria level of patients with PD. Articulation features extracted from continuous speech signals to create i-vectors were the most accurate to quantify the dysarthria level, with correlations of up to 0.69 between the predicted m-FDA scores and those assigned by the phoniatricians. When the dysarthria levels were estimated considering dedicated speech exercises such as rapid repetition of syllables (DDKs) and read texts, the correlations were 0.64 and 0.57, respectively. In addition, the combination of several feature sets and speech tasks improved the results, which validates the hypothesis about the contribution of information from different tasks and feature sets when assessing dysarthric speech signals. The speaker models seem to be promising to perform individual modeling for monitoring the dysarthria level of PD patients. The proposed approach may help clinicians to make more accurate and timely decisions about the evaluation and therapy associated to the dysarthria level of patients. The proposed approach is a great step towards unobtrusive/ecological evaluations of patients with dysarthric speech without the need of attending medical appointments.","tags":["Speech processing","Machine learning","health-care","user-modeling","i-vectors"],"title":"Towards an automatic evaluation of the dysarthria level of patients with Parkinson's disease","type":"publication"},{"authors":["Tomas Arias-Vergara","Juan Camilo Vasquez-Correa","Juan Rafael Orozco-Arroyave","Philipp Klumpp","Elmar Nöth"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"5d3c1e9df918aa3d2b56678903e5d982","permalink":"https://jcvasquezc.github.io/publication/arias-2018-unobtrusive/","publishdate":"2019-08-07T14:58:03.786491Z","relpermalink":"/publication/arias-2018-unobtrusive/","section":"publication","summary":"Parkinson's disease (PD) produces several speech impairments in the patients. Automatic classification of PD patients is performed considering speech recordings collected in noncontrolled acoustic conditions during normal phone calls in a unobtrusive way. A speech enhancement algorithm is applied to improve the quality of the signals. Two different classification approaches are considered: the classification of PD patients and healthy speakers and a multi-class experiment to classify patients in several stages of the disease. According to the results it is possible to classify PD patients and healthy controls with a AUe of up to 0.87. This work is a step forward to the development of telemonitoring systems to assess the speech of the patients.","tags":["Speech processing","Machine learning","health-care","Mobile apps","Apkinson"],"title":"Unobtrusive Monitoring of Speech Impairments of Parkinson's Disease Patients Through Mobile Devices","type":"publication"},{"authors":["Philipp Klumpp","Thomas Janu","Tomás Arias-Vergara","Juan Camilo Vasquez-Correa","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"2d8c0e69922b9d15096fd9448879e70b","permalink":"https://jcvasquezc.github.io/publication/klumpp-2017-apkinson/","publishdate":"2019-08-07T14:57:01.36228Z","relpermalink":"/publication/klumpp-2017-apkinson/","section":"publication","summary":"In this paper we want to present our work on a smartphone application which aims to provide a mobile monitoring solution for patients suffering from Parkinson’s disease. By unobtrusively analyzing the speech signal during phone calls and with a dedicated speech test, we want to be able to determine the severity and the progression of Parkinson’s disease for a patient much more frequently than it would be possible with regular check-ups. The application consists of four major parts. There is a phone call detection which triggers the whole processing chain. Secondly, there is the phone call recording which has proven to be more challenging than expected. The signal analysis, another crucial component, is still in development for the phone call analysis. Additionally, the application collects several pieces of meta information about the calls to put the results into deeper context. After describing how the speech signal is affected by Parkinson’s disease, we sketch the overall application architecture and explain the four major parts of the current implementation in further detail. We then present the promising results achieved with the first version of a dedicated speech test. In the end, we outline how the project could receive further improvements in the future. ","tags":["Speech processing","Mobile apps","Apkinson","Android"],"title":"Apkinson-A Mobile Monitoring Solution for Parkinson's Disease.","type":"publication"},{"authors":["Milos Cernak","Juan Rafael Orozco-Arroyave","Frank Rudzicz","Heidi Christensen","Juan Camilo Vásquez-Correa","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"832a0dee4ed93ee069837613f2dda577","permalink":"https://jcvasquezc.github.io/publication/cernak-2017-characterisation/","publishdate":"2019-08-07T14:57:01.359389Z","relpermalink":"/publication/cernak-2017-characterisation/","section":"publication","summary":"Change in voice quality (VQ) is one of the first precursors of Parkinson’s disease (PD). Specifically, impacted phonation and articulation causes the patient to have a breathy, husky-semiwhisper and hoarse voice. A goal of this paper is to characterise a VQ spectrum – the composition of non-modal phonations – of voice in PD. The paper relates non-modal healthy phonations: breathy, creaky, tense, falsetto and harsh, with disordered phonation in PD. First, statistics are learned to differentiate the modal and non-modal phonations. Statistics are computed using phonological posteriors, the probabilities of phonological features inferred from the speech signal using a deep learning approach. Second, statistics of disordered speech are learned from PD speech data comprising 50 patients and 50 healthy controls. Third, Euclidean distance is used to calculate similarity of non-modal and disordered statistics, and the inverse of the distances is used to obtain the composition of non-modal phonation in PD. Thus, pathological voice quality is characterised using healthy non-modal voice quality “base/eigenspace”. The obtained results are interpreted as the voice of an average patient with PD and can be characterised by the voice quality spectrum composed of 30% breathy voice, 23% creaky voice, 20% tense voice, 15% falsetto voice and 12% harsh voice. In addition, the proposed features were applied for prediction of the dysarthria level according to the Frenchay assessment score related to the larynx, and significant improvement is obtained for reading speech task. The proposed characterisation of VQ might also be applied to other kinds of pathological speech.","tags":["Speech processing","Machine learning","health-care","Computational linguistics"],"title":"Characterisation of voice quality of Parkinson’s disease using differential phonological posterior features","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"35cd781242b4f849fceaa0746d5e05b6","permalink":"https://jcvasquezc.github.io/publication/vasquez-2017-convolutional/","publishdate":"2019-08-07T14:57:01.361025Z","relpermalink":"/publication/vasquez-2017-convolutional/","section":"publication","summary":"Speech impairments are one of the earliest manifestations in patients with Parkinson’s disease. Particularly, articulation deficits related to the capability of the speaker to start/stop the vibration of the vocal folds have been observed in the patients. Those difficulties can be assessed by modeling the transitions between voiced and unvoiced segments from speech. A robust strategy to model the articulatory deficits related to the starting or stopping vibration of the vocal folds is proposed in this study. The transitions between voiced and unvoiced segments are modeled by a convolutional neural network that extracts suitable information from two time-frequency representations: the short time Fourier transform and the continuous wavelet transform. The proposed approach improves the results previously reported in the literature. Accuracies of up to 89% are obtained for the classification of Parkinson’s patients vs. healthy speakers. This study is a step towards the robust modeling of the speech impairments in patients with neuro-degenerative disorders. ","tags":["Speech processing","Deep learning","convolutional neural networks","Wavelets","Machine learning","health-care"],"title":"Convolutional Neural Network to Model Articulation Impairments in Patients with Parkinson's Disease.","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Joan Serra","Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"0e18e96fbd3c9c35db9529363905d0b1","permalink":"https://jcvasquezc.github.io/publication/vasquez-2017-effect/","publishdate":"2019-08-07T14:57:01.361966Z","relpermalink":"/publication/vasquez-2017-effect/","section":"publication","summary":"Automatic detection of Parkinson's disease (PD) from speech is a basic step towards computer-aided tools supporting the diagnosis and monitoring of the disease. Although several methods have been proposed, their applicability to real-world situations is still unclear. In particular, the effect of acoustic conditions is not well understood. In this paper, the effects on the accuracy of five different methods to detect PD from speech are evaluated. Among the considered conditions, background noise produces the worst effect, while dynamic compression or some speech codecs can even have a marginal positive impact. We also consider, for the first time in this context, the problem of mismatches, i.e., when train/test acoustic conditions are different, and observe a high negative impact on all considered methods. Overall, this study is a step forward in performing a continuous monitoring of the neurological state of the patients in non-controlled acoustic conditions.","tags":["Speech processing","Machine learning","health-care"],"title":"Effect of acoustic conditions on algorithms to detect Parkinson's disease from speech","type":"publication"},{"authors":["Nicanor Garcia","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Najim Dehak","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"5c938d2f6d4017d1029c04ba7a976ae0","permalink":"https://jcvasquezc.github.io/publication/garcia-2017-language/","publishdate":"2019-08-07T14:58:03.787039Z","relpermalink":"/publication/garcia-2017-language/","section":"publication","summary":"Speech disorders are among the most common symptoms in patients with Parkinson’s disease. In recent years, several studies have aimed to analyze speech signals to detect and to monitor the progression of the disease. Most studies have analyzed speakers of a single language, even in that scenario the problem remains open. In this study, a cross-language experiment is performed to evaluate the motor impairments of the patients in three different languages: Czech, German and Spanish. The i-vector approach is used for the evaluation due to its capability to model speaker traits. The cosine distance between the i-vector of a test speaker and a reference i-vector that represents either healthy controls or patients is computed. This distance is used to perform two analyses: classification between patients and healthy speakers, and the prediction of the neurological state of the patients according to the MDS-UPDRS score. Classification accuracies of up to 72% and Spearman’s correlations of up to 0.41 are obtained between the cosine distance and the MDS-UPDRS score. This study is a step towards a language independent assessment of patients with neuro-degenerative disorders.","tags":["Speech processing","Machine learning","i-vectors","health-care","Kaldi"],"title":"Language independent assessment of motor impairments of patients with Parkinson’s disease using i-vectors","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Raman Arora","Elmar Nöth","Najim Dehak","Heidi Christensen","Frank Rudzicz","Tobias Bocklet","Milos Cernak","Hamidreza Chinaei"," others"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"fcfdc13d1eacd7a7d613c46af1757e43","permalink":"https://jcvasquezc.github.io/publication/vasquez-2017-multi/","publishdate":"2019-08-07T14:57:01.358204Z","relpermalink":"/publication/vasquez-2017-multi/","section":"publication","summary":"Information from different bio-signals such as speech, handwriting, and gait have been used to monitor the state of Parkinson's disease (PD) patients, however, all the multimodal bio-signals may not always be available. We propose a method based on multi-view representation learning via generalized canonical correlation analysis (GCCA) for learning a representation of features extracted from handwriting and gait that can be used as a complement to speech-based features. Three different problems are addressed: classification of PD patients vs. healthy controls, prediction of the neurological state of PD patients according to the UPDRS score, and the prediction of a modified version of the Frenchay dysarthria assessment (m-FDA). According to the results, the proposed approach is suitable to improve the results in the addressed problems, specially in the prediction of the UPDRS, and m-FDA scores.","tags":["Speech processing","representation learning","handwriting analysis","movement analysis","Inertial sensors","health-care"],"title":"Multi-view representation learning via GCCA for multimodal analysis of Parkinson's disease","type":"publication"},{"authors":["Milos Cernak","Elmar Nöth","Frank Rudzicz","Heidi Christensen","Juan Rafael Orozco-Arroyave","Raman Arora","Tobias Bocklet","Hamidreza Chinaei","Julius Hannink","Phani Sankar Nidadavolu","Juan Camilo Vasquez-Correa"," others"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"3cac6f61dc18f04df862cfd727769c91","permalink":"https://jcvasquezc.github.io/publication/cernak-2017-impact/","publishdate":"2019-08-07T14:57:01.364549Z","relpermalink":"/publication/cernak-2017-impact/","section":"publication","summary":"Different modes of vibration of the vocal folds contribute significantly to the voice quality. The neutral mode phonation, often used in a modal voice, is one against which the other modes can be contrastively described, also called non-modal phonations. This paper investigates the impact of non-modal phonation on phonological posteriors, the probabilities of phonological features inferred from the speech signal using a deep learning approach. Five different non-modal phonations are considered: falsetto, creaky, harshness, tense and breathiness. The impact of such non-modal phonation on phonological features, the Sound Patterns of English (SPE), is investigated in both speech analysis and synthesis tasks. We found that breathy and tense phonation impact the SPE features less, creaky phonation impacts the features moderately, and harsh and falsetto phonation impact the phonological features the most. We also report invariant and the most different SPE features impacted by non-modal phonation.","tags":["Speech processing","Machine learning","health-care","Computational linguistics"],"title":"On the impact of non-modal phonation on phonological features","type":"publication"},{"authors":["Tomas Arias-Vergara","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"4f38e5b9e1552c4b70817e083780df03","permalink":"https://jcvasquezc.github.io/publication/arias-2017-parkinson/","publishdate":"2019-08-07T14:57:01.361654Z","relpermalink":"/publication/arias-2017-parkinson/","section":"publication","summary":"Parkinson’s disease (PD) is a neurological disorder that affects the communication ability of patients. There is interest in the research community to study acoustic measures that provide objective information to model PD speech. Although there are several studies in the literature that consider different characteristics of Parkinson’s speech like phonation and articulation, there are no studies including the aging process as another possible source of impairments in speech. The aim of this work is to analyze the vowel articulation and phonation of Parkinson’s patients compared with respect to two groups of healthy people: (1) young speakers with ages ranging from 22 to 50 years and (2) people with ages matched with respect to the Parkinson’s patients. Each participant repeated the sustained phonation of the five Spanish vowels three times and those utterances per speaker are modeled by using phonation and articulation features. Feature selection is applied to eliminate redundant information in the features space, and the automatic discrimination of the three groups of speakers is performed using a multi-class Support Vector Machine (SVM) following a one vs. all strategy, speaker independent. The results are compared to those obtained using a cognitive-inspired classifier which is based on neural networks (NN). The results indicate that the phonation and articulation capabilities of young speakers clearly differ from those exhibited by the elderly speakers (with and without PD). To the best of our knowledge, this is the first paper introducing experimental evidence to support the fact that age matching is necessary to perform more accurate and robust evaluations of pathological speech signals, especially considering diseases suffered by elderly people, like Parkinson’s. Additionally, the comparison among groups of speakers at different ages is necessary in order to understand the natural change in speech due to the aging process.","tags":["Speech processing","Machine learning","health-care"],"title":"Parkinson's disease and aging: analysis of their effect in phonation and articulation of speech","type":"publication"},{"authors":["Juan Camilo Jiménez-Monsalve","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Pedro Gomez-Vilda"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"eca1ff7d1138cb7199d1491d294ce707","permalink":"https://jcvasquezc.github.io/publication/jimenez-2017-phonation/","publishdate":"2019-08-07T14:58:03.787436Z","relpermalink":"/publication/jimenez-2017-phonation/","section":"publication","summary":"This study considers phonation and articulation measures to model voice disorders produced by three different pathologies: Laryngeal pathologies (LP), cleft lip and palate (CLP), and Parkinson’s disease (PD). Different speech tasks are considered including sustained vowel phonations, isolated words, and read texts. The obtained accuracies, in terms of the area under the ROC curve (AUC), range between 55.7 and 99.2 depending on the pathology. The results suggest that phonation features are appropriate to model LP; however, for the case of CLP and PD, it seems like the articulation measures provide more information about the problems in moving and controlling the articulators of the vocal tract. This work is a step towards the development of methodologies for the automatic discrimination among different voice disorders.","tags":["Speech processing","Machine learning","health-care"],"title":"Phonation and Articulation Analyses in Laryngeal Pathologies, Cleft Lip and Palate, and Parkinson’s Disease","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Reynel Castrillón","Tomas Arias-Vergara","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"05838d1b357119bb2ca9ac9613ccd15b","permalink":"https://jcvasquezc.github.io/publication/vasquez-2017-speaker/","publishdate":"2019-08-07T14:58:03.791023Z","relpermalink":"/publication/vasquez-2017-speaker/","section":"publication","summary":"The progression of the disease in Parkinson’s patients is commonly evaluated with the unified Parkinson’s disease rating scale (UPDRS), which contains several items to assess motor and non–motor impairments. The patients develop speech impairments that can be assessed with a scale to evaluate dysarthria. Continuous monitoring of the patients is suitable to update the medication or the therapy. In this study, a robust speaker model based on the GMM–UBM approach is proposed for the continuous monitoring of the state of Parkinson’s patients. The model is trained with phonation, articulation, and prosody features with the aim of evaluating deficits on each speech dimension. The performance of the model is evaluated in two scenarios: the monitoring of the UPDRS score and the prediction of the dysarthria level of the speakers. The results indicate that the speaker models are suitable to track the disease progression, specially in terms of the evaluation of the dysarthia level of the speakers.","tags":["Speech processing","Machine learning","health-care","user-modeling"],"title":"Speaker Model to Monitor the Neurological State and the Dysarthria Level of Patients with Parkinson’s Disease","type":"publication"},{"authors":["Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla","Juan Camilo Vásquez-Correa","Cesar German Castellanos-Domı́nguez","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"8d03a7a260ec75fd43e00660a56bb0ec","permalink":"https://jcvasquezc.github.io/publication/orozco-2016-automatic/","publishdate":"2019-08-07T14:58:03.78781Z","relpermalink":"/publication/orozco-2016-automatic/","section":"publication","summary":"This paper presents a system for the automatic detection of hypernasal speech signals based on the combination of two different characterization approaches applied to the five Spanish vowels and two selected words. First one is based on classical features such as pitch period perturbations, noise measures, and Mel-Frequency Cepstral Coefficients (MFCC). Second is based on the non-linear dynamics (NLD) analysis. The most relevant features are selected and sorted according to two techniques: principal components analysis (PCA), and sequential floating feature selection (SFFS). The decision about whether a voice record is hypernasal or healthy is taken using a soft margin - support vector machine (SM-SVM). The experiments are carried out using recordings of the five Spanish vowels and the words /coco/ and /gato/, considering three different set of features: (1) the classical approach, (2) the NLD analysis, and (3) the combination of the classical and NLD measures. In general, the accuracy rates are higher and more stable when the classical and NLD features are combined into the same feature space, indicating that the NLD analysis is a complement for the classical approach.","tags":["Speech processing","non-linear dynamics","Machine learning","health-care"],"title":"Automatic detection of hypernasal speech of children with cleft lip and palate from spanish vowels and words using classical measures and nonlinear analysis","type":"publication"},{"authors":["Juan Camilo Vásquez Correa"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"153ab4f1159f1eacb9e05f7dd10d1f04","permalink":"https://jcvasquezc.github.io/publication/vasquez-2016-emotion/","publishdate":"2019-08-07T14:58:03.788208Z","relpermalink":"/publication/vasquez-2016-emotion/","section":"publication","summary":"In the last years, there has a great progress in automatic speech recognition. The challenge now it is not only recognize the semantic content in the speech but also the called 'paralinguistic' aspects of the speech, including the emotions, and the personality of the speaker. This research work aims in the development of a methodology for the automatic emotion recognition from speech signals in non-controlled noise conditions. For that purpose, different sets of acoustic, non-linear, and wavelet based features are used to characterize emotions in different databases created for such purpose. The acoustic analysis considers a standard feature set developed for emotion recognition from speech called OpenEAR, and a set of spectral and noise derived measures.  The non-linear analysis is based on non-linear dynamic measures and include the correlation dimension, the largest Lyapunov exponent, the Hurst exponent, and the Lempel Ziv complexity. Also it is proposed a set of measures derived from parametric non-stationary analysis using time dependent ARMA models. The wavelet based measures consider features derived from the wavelet packet transform, and different wavelet time-frequency representations such as the bionic wavelet transform, and the synchro-squeezed wavelet transform. Different non-controlled noise conditions are tested considering four different scenarios: (1) the original recordings, (2) the signals degraded by two additive noisy environments: street and a cafeteria babble, (3) the re-captured signals in two natural noisy environments asstreet and office, and (4) the recordings compressed by seven different codecs used for the transmission through mobile, VoIP, and web based telephone channels. Also two different speech enhancement algorithms are tested to evaluate if they are suitable to improve the results in the classification of emotions in noisy speech signals. A classification scheme based on the combination of Gaussian mixture models and Support vector machines is used for the analysis","tags":["Speech processing","Wavelets","Paralinguistics","Emotion recognition","Machine learning","non-linear dynamics"],"title":"Emotion recognition from speech with acoustic, non-linear and wavelet-based features extracted in different acoustic conditions","type":"publication"},{"authors":["Tomas Arias-Vergara","Juan Camilo Vasquez-Correa","Juan Rafael Orozco-Arroyave","Jesus Francisco Vargas-Bonilla","Tino Haderlein","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"a1b335eac1885886d0431600f084fdb5","permalink":"https://jcvasquezc.github.io/publication/arias-2016-gender/","publishdate":"2019-08-07T14:57:01.36423Z","relpermalink":"/publication/arias-2016-gender/","section":"publication","summary":"Parkinson’s disease (PD) severity is evaluated by neurologist experts by means of several tests. One of them is the Movement Disorder Society–Unified Parkinson’s Disease Rating Scale (MDS–UPDRS). The main hypothesis is that changes in the speech of PD patients reflect changes in their neurological state. In this study we use the Gaussian Mixture Model Universal Background Model approach to track the disease progression per speaker. Speech recordings from 62 PD patients were captured from 2012 to 2015 in three recording sessions. The validation of the models is performed with recordings of 7 patients (3 male and 4female). All of the patients were diagnosed by a neurologist expert according to the MDS–UPDRS–III score. The models were trained using speech recordings from male and female patients separately. According to the results, it is possible to track the disease progression with a Pearson’s correlation of up to 0.88 for males and 0.53 for females with respect to the MDS–UPDRS–III labels.","tags":["Speech processing","Machine learning","health-care","user-modeling"],"title":"Gender-dependent gmm-ubm for tracking parkinson's disease progression from speech","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Julian David Arias-Londoño","Jesús Francisco Vargas-Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"378192ab1d126dffeebf045fac585332","permalink":"https://jcvasquezc.github.io/publication/vasquez-2016-non/","publishdate":"2019-08-07T14:57:01.360378Z","relpermalink":"/publication/vasquez-2016-non/","section":"publication","summary":"A new set of features based on non-linear dynamics measures obtained from the wavelet packet transform for the automatic recognition of “fear-type” emotions in speech is proposed. The experiments are carried out using three different databases with a Gaussian Mixture Model for classification. The results indicate that the proposed approach is promising for modeling “fear-type” emotions in speech.","tags":["Speech processing","Wavelets","Paralinguistics","Emotion recognition","Machine learning","non-linear dynamics"],"title":"Non-linear dynamics characterization from wavelet packet transform for automatic recognition of emotional speech","type":"publication"},{"authors":["Tomas Arias-Vergara","Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"e6470a5108a1d0719a76123ec25f6c75","permalink":"https://jcvasquezc.github.io/publication/arias-2016-parkinson/","publishdate":"2019-08-07T14:57:01.36007Z","relpermalink":"/publication/arias-2016-parkinson/","section":"publication","summary":"Gaussian Mixture Model Universal Background Model (GMM-UBM) approach is used to assess the Parkinson’s disease (PD) progression per speaker. The disease progression is assessed individually per patient following a user modeling-approach. Voiced and unvoiced segments are extracted and grouped separately to train the models. Additionally, the Bhattacharyya distance is used to estimate the difference between the UBM and the user model. Speech recordings from 62 PD patients (34 male and 28 female) were captured from 2012 to 2015 in four recording sessions. The validation of the models is performed with recordings of 7 patients. All of the patients were diagnosed by a neurologist expert according to the MDS-UPDRS-III scale. The features used to model the speech of the patients are validated by doing a regression based on a Support Vector Regressor (SVR). According to the results, it is possible to track the disease progression with a Pearson’s correlation of up to 0.60 with respect to the MDS-UPDRS-III labels.","tags":["Speech processing","Machine learning","health-care","user-modeling"],"title":"Parkinson's Disease Progression Assessment from Speech Using GMM-UBM.","type":"publication"},{"authors":["Juan Rafael Orozco-Arroyave","Juan Camilo Vasquez-Correa","Florian Hönig","Julián David Arias-Londono","Jesús Francisco Vargas-Bonilla","Sabine Skodda","Jan Rusz","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"81d485aec446fa1f6bc309e3713a2122","permalink":"https://jcvasquezc.github.io/publication/orozco-2016-towards/","publishdate":"2019-08-07T14:57:01.357183Z","relpermalink":"/publication/orozco-2016-towards/","section":"publication","summary":"The suitability of articulation measures and speech intelligibility is evaluated to estimate the neurological state of patients with Parkinson's disease (PD). A set of measures recently introduced to model the articulatory capability of PD patients is considered. Additionally, the speech intelligibility in terms of the word accuracy obtained from the Google® speech recognizer is included. Recordings of patients in three different languages are considered: Spanish, German, and Czech. Additionally, the proposed approach is tested on data recently used in the INTERSPEECH 2015 Computational Paralinguistics Challenge. According to the results, it is possible to estimate the neurological state of PD patients from speech with a Spearman's correlation of up to 0.72 with respect to the evaluations performed by neurologist experts.","tags":["Speech processing","Speech recognition","Machine learning","health-care"],"title":"Towards an automatic monitoring of the neurological state of Parkinson's patients from speech","type":"publication"},{"authors":["Juan Camilo Vasquez-Correa","Tomas Arias-Vergara","Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla","Elmar Noeth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"76289bb4de8190ca12eb9ce81d8fc349","permalink":"https://jcvasquezc.github.io/publication/vasquez-2016-wavelet/","publishdate":"2019-08-07T14:57:01.363882Z","relpermalink":"/publication/vasquez-2016-wavelet/","section":"publication","summary":"The interest in emotion recognition from speech has increased in the last decade. Emotion recognition can improve the quality of services and the quality of life of people. One of the main problems in emotion recognition from speech is to find suitable features to represent the phenomenon. This paper proposes new features based on the energy content of wavelet based time-frequency (TF) representations to model emotional speech. Three TF representations are considered: (1) the continuous wavelet transform, (2) the bionic wavelet transform, and (3) the synchro-squeezed wavelet transform. The classification is performed using GMM supervectors. Different classification problems are addressed, including high vs. low arousal, positive vs. negative valence, and multiple emotions. The results indicate that the proposed features are useful to classify high vs. low arousal emotions, and that the features derived from the synchro-squeezed wavelet transform are more suitable than the other two approaches to model emotional speech.","tags":["Speech processing","Wavelets","Paralinguistics","Emotion recognition","Machine learning"],"title":"Wavelet-based time-frequency representations for automatic recognition of emotions from speech","type":"publication"},{"authors":["Juan Camilo Vasquez-Correa","Juan Rafael Orozco-Arroyave","Elmar Nöth"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"3c086f3152bdad466cbeeee19165496a","permalink":"https://jcvasquezc.github.io/publication/vasquez-2016-word/","publishdate":"2019-08-07T14:57:01.359744Z","relpermalink":"/publication/vasquez-2016-word/","section":"publication","summary":"Parkinson's disease patients develop several impairments related to the speech production process. The deficits of the speech of the patients include reduction in the phonation, articulation, prosody and intelligibility capabilities. Related studies have analyzed the phonation, articulation and prosody of the patients with Parkinson's, while the intelligibility impairments have not been enough evaluated. In this study we propose two novel features based on the word accuracy and the dynamic time warping algorithm with the aim of assess the intelligibility deficits of the patients using an automatic speech recognition system. We evaluate the suitability of the features by the automatic classification of utterances of patients vs. healthy controls, and by predicting automatically the neurological state of the patients. According to results, an accuracy of up to 92% is obtained, indicating that the proposed features are highly accurate to detect Parkinson's disease from speech. Regarding the automatic monitoring of the neurological state, the proposed approach could be used as complement of other features derived from speech or other bio-signals to monitor the neurological state of the patients.","tags":["Speech processing","Speech recognition","health-care","Machine learning"],"title":"Word accuracy and dynamic time warping to assess intelligibility deficits in patients with parkinsons disease","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Tomas Arias-Vergara","Juan Rafael Orozco-Arroyave","Jesús Francisco Vargas-Bonilla","Julián D Arias-Londoño","Elmar Nöth"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"7f4970f463cc5b89985ef31095396033","permalink":"https://jcvasquezc.github.io/publication/vasquez-2015-automatic/","publishdate":"2019-08-07T14:57:01.358998Z","relpermalink":"/publication/vasquez-2015-automatic/","section":"publication","summary":"Automatic classification of Parkinson's disease (PD) speakers and healthy controls (HC) is performed considering speech recordings collected in non-controlled noise conditions. The speech tasks include six sentences and a read text. The recording is performed using an open source portable device and a commercial microphone. A speech enhancement (SE) technique is applied to improve the quality of the signals. Voiced and unvoiced frames are segmented from the speech tasks and characterized separately. The discrimination of speakers with PD and HC is performed using a support vector machine with soft margin. The results indicate that it is possible to discriminate between PD and HC speakers using recordings collected in non-controlled noise conditions. The accuracies obtained with the voiced features range from 64% to 86%. For unvoiced features the accuracies range from 78% to 99%. The SE algorithm improves the accuracies of the unvoiced frames in up to 11 percentage points, while the accuracies decrease in the voiced frames when the SE algorithm is applied. This work is a step forward to the development of portable devices to assess the speech of people with PD. ","tags":["speech processing","health-care","Machine learning"],"title":"Automatic detection of Parkinson's disease from continuous speech recorded in non-controlled noise conditions","type":"publication"},{"authors":["Nicanor Garcı́a","Juan Camilo Vásquez-Correa","Julian David Arias-Londoño","Jesus Francisco Várgas-Bonilla","Juan Rafael Orozco-Arroyave"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"61946905f80b1c67aa400c7f94fa6087","permalink":"https://jcvasquezc.github.io/publication/garcia-2015-automatic/","publishdate":"2019-08-07T14:57:01.36258Z","relpermalink":"/publication/garcia-2015-automatic/","section":"publication","summary":"Automatic recognition of emotions in speech has attracted the attention of the research community in recent years. Some of the most relevant proposed applications of it are in call-centers. In these scenarios the speech is distorted by compression algorithms. The effects of such distortion on the performance of systems for automatic recognition of emotions must be assessed. In this study these effects are evaluated independently of any other distortions generated by the communications channel. Several state-of-the-art codecs are used to compress the speech signals of two emotional speech databases. The databases used are the Berlin Database of Emotional Speech and the enterface05. The methodology considers voiced and unvoiced segments of the speech separately. Spectral, cepstral, noise and Non-Linear Dynamics (NLD) measures are used to characterize the segments. Finally, a classifier based on a Gaussian Mixture Model (GMM) is used to identify the emotion. The results indicate that voiced segments are less affected by the compression than unvoiced ones in terms in classification accuracy. They also show that the bandwidth of the analyzed signals is an important factor in the classification results.","tags":["Speech processing","Machine learning","non-linear dynamics","Emotion recognition","Paralinguistics"],"title":"Automatic emotion recognition in compressed speech using acoustic and non-linear features","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Nicanor Garcı́a","Juan Rafael Orozco-Arroyave","Julián David Arias-Londoño","Jesús Francisco Vargas-Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"bcfe1a1d89bc5c95c3ec359e528dddb9","permalink":"https://jcvasquezc.github.io/publication/vasquez-2015-emotion/","publishdate":"2019-08-07T14:57:01.360692Z","relpermalink":"/publication/vasquez-2015-emotion/","section":"publication","summary":"Automatic emotion recognition considering speech signals has attracted the attention of the research community in the last years. One of the main challenges is to find suitable features to represent the affective state of the speaker. In this paper, a new set of features derived from the wavelet packet transform is proposed to classify different negative emotions such as anger, fear, and disgust, and to differentiate between those negative emotions and neutral state, or positive emotions such as happiness. Different wavelet decompositions are considered both for voiced and unvoiced segments, in order to determine a frequency band where the emotions are concentrated. Several measures are calculated in the wavelet decomposed signals, including log-energy, entropy measures, mel frequency cepstral coefficients, and the Lempel-Ziv complexity. The experiments consider two different databases extensively used in emotion recognition: the Berlin emotional database, and the enterface05 database. Also, in order to approximate to real-world conditions in terms of the quality of recorded speech, such databases are degraded using different environmental noise such as cafeteria babble, and street noise. The addition of noise is performed considering several signal to noise ratio levels which range from -3 to 6 dB. Finally, the effect produced by two different speech enhancement methods is evaluated. According to results, the features calculated from the lower frequency wavelet decomposition coefficients are able to recognize the fear-type emotions in speech. Also, one of the speech enhancement algorithms has proven to be useful to improve of the accuracy in cases of speech signals affected by highly background noise.","tags":["Speech processing","Wavelets","Paralinguistics","Emotion recognition","Machine learning"],"title":"Emotion recognition from speech under environmental noise conditions using wavelet decomposition","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Julián D Arias-Londoño","Jesús Francisco Vargas-Bonilla","LD Avendaño","Elmar Nöth"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"0bbbba9fb117f660bc63f8cc01d2d238","permalink":"https://jcvasquezc.github.io/publication/vasquez-2015-time/","publishdate":"2019-08-07T14:58:03.788536Z","relpermalink":"/publication/vasquez-2015-time/","section":"publication","summary":"The speech signals are non-stationary processes with changes in time and frequency. The structure of a speech signal is also affected by the presence of several paralinguistics phenomena such as emotions, pathologies, cognitive impairments, among others. Non-stationarity can be modeled using several parametric techniques. A novel approach based on time dependent auto-regressive moving average (TARMA) is proposed here to model the non-stationarity of speech signals. The model is tested in the recognition of “fear-typeo” emotions in speech. The proposed approach is applied to model syllables and unvoiced segments extracted from recordings of the Berlin and enterface05 databases. The results indicate that TARMA models can be used for the automatic recognition of emotions in speech.","tags":["Speech processing","Paralinguistics","Emotion recognition","Machine learning"],"title":"Time dependent ARMA for automatic recognition of fear-type emotions in speech","type":"publication"},{"authors":["Nicanor Garcı́a","Juan Camilo Vásquez-Correa","Jesus Francisco Várgas-Bonilla","Julian David Arias-Londono","Juan Rafael Orozco-Arroyave"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"6ed4a870302e1a425c3e627f0dd09699","permalink":"https://jcvasquezc.github.io/publication/garcia-2014-evaluation/","publishdate":"2019-08-07T14:58:03.791478Z","relpermalink":"/publication/garcia-2014-evaluation/","section":"publication","summary":"The estimation of the fundamental frequency (F0) in speech is a very important task that has been addressed by many researchers. F0 estimation can be used to separate two kind of frames from an utterance, those where the vocal folds vibrate (voiced sounds) and those where not (unvoiced sounds). The methods used to estimate F0 are affected by the presence of additive noise in recordings made in non-controlled environments, however, there are different techniques to mitigate the effect of such noise and Speech Enhancement (SE) has proven to be one of the most effective ones. This article presents results of the evaluation of the effects of noise and SE algorithms on the detection of F0 and the signal segmentation in voiced/unvoiced segments. We performed experiments with signals artificially contaminated with two different kinds of noise, White Gaussian Noise (WGN) and background noise recorded at a cafeteria (Cafeteria babble), subsequently, the signals are processed with SE algorithms of four different classes: Wiener Filter, Spectral Subtraction, Statistical-Model Based and Sub-space algorithms. Two different kind of error metrics are considered: Gross Pitch Error and Voicing Determination Error. The results show that only the sub-space approach improves the performance in the detection of F0 and the signal segmentation in voiced/unvoicd segments.","tags":["Speech processing","Speech enhancement"],"title":"Evaluation of the effects of speech enhancement algorithms on the detection of fundamental frequency of speech","type":"publication"},{"authors":["Juan Camilo Vásquez-Correa","Nicanor Garcı́a","Jesús Francisco Vargas-Bonilla","Juan Rafael Orozco-Arroyave","Julián David Arias-Londoño","Olga Lucia Quintero"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"c8962d3a43c09ade58ab6fdcd5fc7cb1","permalink":"https://jcvasquezc.github.io/publication/vasquez-2014-evaluation/","publishdate":"2019-08-07T14:57:01.361329Z","relpermalink":"/publication/vasquez-2014-evaluation/","section":"publication","summary":"Detection of emotion in humans from speech signals is a recent research field. One of the scenarios where this field has been applied is in situations where the human integrity and security are at risk. In this paper we are propossing a set of features based on the Teager energy operator, and several entropy measures obtained from the decomposition signals from discrete wavelet transform to characterize different types of negative emotions such as anger, anxiety, disgust, and desperation. The features are measured in three different conditions: (1) the original speech signals, (2) the signals that are contaminated with noise, or are affected by the presence of a phone channel, and (3) the signals that are obtained after processing using an algorithm for Speech Enhancement based on Karhunen-Love Transform. According to the results, when the speech enhancement is applied, the detection of emotion in speech is increased in up to 22% compared to results obtained when the speech signal is highly contaminated with noise.","tags":["Speech processing","Wavelets","Paralinguistics","Emotion recognition","Machine learning"],"title":"Evaluation of wavelet measures on automatic detection of emotion in noisy and telephony speech signals","type":"publication"},{"authors":["Juan Camilo Vásquez Correa","Juan Rafael Orozco Arroyave","Julián David Arias-Londoño","Jesús Francisco Vargas Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"eac1987cf736406509a439a47d3e8d9c","permalink":"https://jcvasquezc.github.io/publication/vasquez-2014-new/","publishdate":"2019-08-07T14:57:01.357808Z","relpermalink":"/publication/vasquez-2014-new/","section":"publication","summary":"Parkinson's disease (PD) is a neurodegenerative disorder that affects the coordination of muscles and limbs, including those responsible of the speech production. The lack of control ofthe limbs and muscles involved in the speech production process can generate intelligibility problems and this situation has a negative impact in the social interaction of the patients. It is already demonstrated that constant speech therapy can improve the communication abilities of the patients; however, the measurement of the recovery progress is done subjectively by speech therapists and neurologists. Due to this, it is required the development of flexible tools able to asses and guide the speech therapy of the patients. In this paper the design and deployment of a new device for the real time assessment of speech signals of people with PD is presented. The processes of design and deployment include the development on three platforms: first, a graphic user interface is developed on Matlab, second the first prototype is implemented on a digital signal processor (DSP) and third, the final device is developed on a mini-computer. The device is equipped with an audio codec, storage capacity and the processing unit. Besides, the system is complemented with a monitor to display the processed information on real time and with a keyboard enabling the interaction of the end-user with the device. Different acoustics and nonlinear dynamics measures which have been used in the state of the art for the assessment of speech of people with PD are implemented on the three mentioned platforms. In accordance with the state of the art, the designed platforms show an increment in the variation of the fundamental period of speech (commonly called pitch) of people with PD. Additionally, the decrease of the vocal space area is validated for the case of patients with PD. These results indicate that the designed device is useful to perform the assessment and monitoring of the speech therapy of people with PD.","tags":["speech processing","health-care"],"title":"New computer aided device for real time analysis of speech of people with Parkinson's disease","type":"publication"},{"authors":["University of Antioquia","COLCIENCIAS"],"categories":[],"content":"Parkinson\u0026rsquo;s Disease (PD) is the second neurological condition more prevalent after Alheimer. It is fundamental identify early markers of the disease. 90% of people with PD present speech disorders, but only from 3% to 4% recieve speech treatment. In this project will be developed methodologies based on signal processing to establish if the speech signals represent an early marker of PD. Also will be applied machine learning techniques to develop methodologies that allow make an objective following about of speech quality in patients with PD.\n","date":1376143811,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376143811,"objectID":"f9bed188b01816a26fc83da4166c5dca","permalink":"https://jcvasquezc.github.io/project/pdspeech/","publishdate":"2013-08-10T09:10:11-05:00","relpermalink":"/project/pdspeech/","section":"project","summary":"Analysis of the discriminant capacity of phonation, articulation and prosody features from patients with Parkinson's disease on preclinic and advanced stages for the development of computer aided tools for supporting the diagnosis and monitoring of the patients","tags":["Health-care","Signal processing","Speech processing"],"title":"PD speech","type":"project"},{"authors":["Juan Camilo Vásquez-Correa","Juan Rafael Orozco-Arroyave","Julian David Arias-Londono","Jesus Francisco Vargas-Bonilla","Elmar Nöth"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"b428f51d82f9f313cafb9b2239d7180d","permalink":"https://jcvasquezc.github.io/publication/vasquez-2013-design/","publishdate":"2019-08-07T14:57:01.364887Z","relpermalink":"/publication/vasquez-2013-design/","section":"publication","summary":"Parkinsons disease (PD) is a neurodegenerative disorder that affects the coordination and regulation of muscles and limbs, including those responsible of speech production, resulting alterations in voice intelligibility. It is already demonstrated that the constant speech therapy can improve the communication skills of the patients; however, it is required the development of flexible tools able to assess and guide the speech therapy of the patients without the intervention of the experts. In this paper one embedded system for the real time analysis of speech from people with Parkinson's disease is presented. Two platforms are developed. First, a Matlab Graphical User Interface is presented; second, the application is deployed in a minicomputer that has an audio codec, storage capacity and a efficient processing unit. The device has been equipped with an LCD monitor to display the information on real time, and a mini keyboard for the interface with the user. Different measurements that are commonly used in the assessment of speech from people with PD are evaluated. In agreement with the state of the art, an increment of the pitch variation is showed for patients with PD, additionally, lower values of the vowel space area (VSA) are also shown for speech recordings uttered by people with PD","tags":["speech processing","health-care"],"title":"Design and implementation of an embedded system for real time analysis of speech from people with parkinson's disease","type":"publication"}]